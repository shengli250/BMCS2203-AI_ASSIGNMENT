import streamlit as st
import numpy as np
import joblib
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import re
# å¯¼å…¥ MLPClassifier æ¥è·å–ç±»å‹æç¤º (å¯é€‰)
from sklearn.neural_network import MLPClassifier 

# --- Configuration Parameters ---
MAX_SEQUENCE_LENGTH = 20 # Although less relevant for TFIDF, keeping it for context
CONFIDENCE_THRESHOLD = 0.70 # è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼åˆ™è§†ä¸ºâ€œæ— æ³•è¯†åˆ«çš„æ„å›¾â€

# --- A. CHATBOT RESPONSE LOOKUP TABLE ---
RESPONSE_DICT = {
    "ask_room_price": "Our standard room price is 150 MYR per night, and a deluxe room is 250 MYR. Which room type would you like to inquire about?",
    "ask_availability": "Could you please provide the check-in and check-out dates? I can check real-time room availability for you.",
    "ask_facilities": "We offer free Wi-Fi, complimentary parking, an indoor swimming pool, and a 24-hour gym.",
    "ask_location": "Our hotel is situated in the city center, close to the central station and major shopping areas. You can find the full address on our website.",
    "ask_checkin_time": "Our standard check-in time is 3:00 PM. Please contact the front desk if you require early check-in.",
    "ask_checkout_time": "Please ensure you check out before 12:00 PM (noon). Late check-outs may incur an additional charge.",
    "ask_booking": "You can make a reservation through our official website, by calling our booking hotline, or via major online travel platforms.",
    "ask_cancellation": "Our cancellation policy depends on your booking type. Generally, cancellation is free if done 24 hours in advance.",
    "greeting": "Hello! I am happy to assist you. How may I help you with your booking or answer your questions?",
    "goodbye": "Thank you for reaching out! Have a wonderful day. Feel free to contact me if you have any other questions.",
    # Default response for unrecognized intents
    "unrecognized_intent": "I apologize, but I currently cannot understand your request. Could you please try rephrasing your question?", 
}

# --- B. NLTK Download and Preprocessing Setup ---
# ä½¿ç”¨ st.cache_resource æ¥ç¡®ä¿ NLTK èµ„æºåªä¸‹è½½ä¸€æ¬¡
@st.cache_resource(show_spinner="Downloading NLTK resources...")
def download_nltk_resources():
    """Downloads necessary NLTK resources into the Streamlit cache."""
    try:
        nltk.download('punkt', quiet=True)
        nltk.download('punkt_tab', quiet=True) # This may not be necessary
        nltk.download('wordnet', quiet=True)
        nltk.download('stopwords', quiet=True)
        return True
    except Exception as e:
        st.error(f"Failed to download NLTK resources: {e}")
        return False

# æ‰§è¡Œ NLTK èµ„æºä¸‹è½½
if download_nltk_resources():
    # åªæœ‰ä¸‹è½½æˆåŠŸåæ‰åˆå§‹åŒ– NLTK å¯¹è±¡
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()
else:
    # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨ç©ºé›†å’Œ None æ¥é¿å…åç»­é”™è¯¯
    stop_words = set()
    lemmatizer = None

def preprocess_text(text):
    """Applies the same preprocessing steps as the training script."""
    if not lemmatizer:
        return "" # Handle case where NLTK setup failed
        
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    tokens = word_tokenize(text)
    tokens = [word for word in tokens if word not in stop_words]
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return ' '.join(tokens)

# --- C. Model Loading and Caching ---
@st.cache_resource
def load_resources():
    """Loads the model, vectorizer, and label encoder from files."""
    try:
        # Load MLPClassifier Model
        ann_model = joblib.load('ann_intent_model.joblib')
        
        # Load TFIDF Vectorizer
        vectorizer = joblib.load('tfidf_vectorizerANN.joblib')
        
        # Load LabelEncoder
        le = joblib.load('label_encoder.joblib')
        
        return ann_model, vectorizer, le
    except FileNotFoundError as e:
        st.error(f"Error loading required model files. Please ensure all files (ann_intent_model.joblib, tfidf_vectorizerANN.joblib, label_encoder.joblib) are in the same directory. Missing file: {e.filename}")
        return None, None, None

ann_model, vectorizer, le = load_resources()

# --- D. Prediction Function ---
def predict_intent(text):
    """
    Predicts the intent using the ANN model and applies a confidence threshold.
    """
    if ann_model is None or vectorizer is None or le is None or not lemmatizer:
        return "setup_error", RESPONSE_DICT.get("unrecognized_intent"), "N/A"

    # 1. Preprocessing and Feature Extraction
    user_input_cleaned = preprocess_text(text)
    vector = vectorizer.transform([user_input_cleaned])

    # 2. Get Probability Predictions
    # MLPClassifier provides probabilities via predict_proba
    predictions_proba = ann_model.predict_proba(vector)[0]
    
    # Get the index (ID) of the highest probability
    predicted_id = np.argmax(predictions_proba)
    # Get the confidence score (the highest probability)
    confidence_score = np.max(predictions_proba)
    
    # 3. Apply Confidence Threshold Logic
    if confidence_score < CONFIDENCE_THRESHOLD:
        intent_name = "unrecognized_intent"
        response = RESPONSE_DICT.get(intent_name)
    else:
        # Convert the predicted ID back to the intent name
        intent_name = le.inverse_transform([predicted_id])[0]
        # Retrieve the specific response for the predicted intent
        response = RESPONSE_DICT.get(intent_name, RESPONSE_DICT['unrecognized_intent'])

    confidence_display = f"{confidence_score*100:.2f}%"
    
    return intent_name, response, confidence_display


# --- E. Streamlit App Layout ---
def main():
    st.set_page_config(page_title="ANN Intent Chatbot (TF-IDF)", layout="centered")

    st.title("ğŸ¤– Hotel Intent Recognition Chatbot (ANN)")
    st.markdown("åŸºäº **TF-IDF** å’Œ **Scikit-learn MLPClassifier (ANN)** æ¨¡å‹")

    st.info(f"**Confidence Threshold for Unrecognized Intent:** {CONFIDENCE_THRESHOLD*100:.0f}%")
    
    # User Input
    user_input = st.text_input("**Your Query:**", placeholder="E.g., I want to book a room. Do you have a gym?")
    
    # Create the button ONLY ONCE
    button_clicked = st.button("ğŸš€ **Get Chatbot Response**") 

    if button_clicked:
        if user_input:
            with st.spinner('Analyzing query...'):
                # Predict the intent
                intent_name, response, confidence_display = predict_intent(user_input)
                
                # --- Display Results ---
                st.markdown("---")
                
                st.subheader("ğŸ’¡ Analysis Result")
                
                # Highlight the predicted intent
                if intent_name == "unrecognized_intent" or intent_name == "setup_error":
                    st.error(f"**Predicted Intent:** `{intent_name}` (Confidence: {confidence_display})")
                else:
                    st.success(f"**Predicted Intent:** `{intent_name}` (Confidence: {confidence_display})")

                st.subheader("ğŸ’¬ Chatbot Response")
                st.markdown(f"> **{response}**")
                
        else:
            # Handle the case where the button is clicked but the input is empty
            st.warning("Please enter a query to get a response.")

if __name__ == "__main__":
    main()
