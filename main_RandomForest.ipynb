{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039eb09b-bded-48cc-96ab-08e33c67aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Resources downloaded successfully!\n",
      "                           text              intent\n",
      "0               Zero tolerance?  ask_smoking_policy\n",
      "1            Is the hotel open?    ask_availability\n",
      "2  Are there fines for smoking?  ask_smoking_policy\n",
      "3            Cancel reservation    ask_cancellation\n",
      "4            Traveling with dog      ask_pet_policy\n",
      "--- Preprocessing Complete (with NLTK Lemmatization) ---\n",
      "                           text        cleaned_text\n",
      "0               Zero tolerance?      zero tolerance\n",
      "1            Is the hotel open?          hotel open\n",
      "2  Are there fines for smoking?        fine smoking\n",
      "3            Cancel reservation  cancel reservation\n",
      "4            Traveling with dog       traveling dog\n",
      "Feature matrix X shape: (2001, 974)\n",
      "Labels y shape: (2001,)\n",
      "Train set size:1600 samples\n",
      "Test set size:401 samples\n",
      "--- Random Forest Model Evaluation ---\n",
      "Accuracy: 0.6932668329177057\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "  ask_airport_transfer       0.80      0.80      0.80        20\n",
      "      ask_availability       0.75      0.60      0.67        20\n",
      "           ask_booking       0.75      0.90      0.82        20\n",
      " ask_breakfast_details       0.76      0.65      0.70        20\n",
      "      ask_cancellation       0.85      0.85      0.85        20\n",
      "      ask_checkin_time       0.67      0.60      0.63        20\n",
      "     ask_checkout_time       0.60      0.75      0.67        20\n",
      "      ask_child_policy       0.82      0.43      0.56        21\n",
      "   ask_contact_support       0.82      0.70      0.76        20\n",
      "        ask_facilities       0.61      0.55      0.58        20\n",
      "          ask_location       0.58      0.55      0.56        20\n",
      "         ask_lost_item       0.62      0.65      0.63        20\n",
      "   ask_luggage_storage       0.76      0.65      0.70        20\n",
      "ask_nearby_attractions       0.33      0.80      0.47        20\n",
      "   ask_payment_methods       0.83      0.75      0.79        20\n",
      "        ask_pet_policy       0.94      0.85      0.89        20\n",
      "        ask_room_price       0.83      0.95      0.88        20\n",
      "    ask_smoking_policy       0.88      0.75      0.81        20\n",
      "               goodbye       1.00      0.30      0.46        20\n",
      "              greeting       0.57      0.80      0.67        20\n",
      "\n",
      "              accuracy                           0.69       401\n",
      "             macro avg       0.74      0.69      0.70       401\n",
      "          weighted avg       0.74      0.69      0.70       401\n",
      "\n",
      "Model and Vectorizer saved using joblib.\n",
      "\n",
      "--- Loading Responses from JSON ---\n",
      "Successfully loaded 20 intent-response pairs.\n",
      "\n",
      " --- Random Forest Chatbot Test ---\n",
      "User Input: What time can I check in?\n",
      "Chatbot Reply: Check-in starts at 3:00 PM. Early check-in is subject to availability. You can drop your luggage at the concierge for free if you arrive early. Please note that a security deposit is required upon check-in, which will be refunded upon check-out.\n"
     ]
    }
   ],
   "source": [
    "# install necessary libraries (assuming the initial block has been run)\n",
    "# !pip install scikit-learn\n",
    "# !pip install pandas\n",
    "# !pip install nltk\n",
    "\n",
    "# download necessary nltk resources (assuming the initial block has been run)\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "print(\"NLTK Resources downloaded successfully!\")\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ğŸŒŸ æ›¿æ¢ï¼šå¯¼å…¥éšæœºæ£®æ—åˆ†ç±»å™¨ (Random Forest Classifier)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from joblib import dump,load\n",
    "\n",
    "# Import NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Initialize NLTK resources\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Placeholder: Load the actual dataset. Ensure it has 'text' (user query) and 'intent' (label) columns\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# shuffle the data for robust splitting\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(df.head())\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Convert to Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove Punctuation and Special Characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # 3. Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # 4. Stopword Removal\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # 5. Lemmatization (Key Enhancement)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Rejoin tokens into a single string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the new preprocessing function to the text column\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(\"--- Preprocessing Complete (with NLTK Lemmatization) ---\")\n",
    "print(df[['text', 'cleaned_text']].head())\n",
    "\n",
    "# Prepare the cleaned text and intents for the model training section\n",
    "X = df['cleaned_text']\n",
    "y = df['intent']\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data to create the feature matrix X\n",
    "X = vectorizer.fit_transform(X)\n",
    "y = df['intent']\n",
    "\n",
    "print(f\"Feature matrix X shape: {X.shape}\")\n",
    "print(f\"Labels y shape: {y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y if len(df['intent'].unique()) > 1 else None, # ä»…åœ¨æœ‰å¤šä¸ªç±»åˆ«æ—¶åˆ†å±‚\n",
    ")\n",
    "\n",
    "print(f\"Train set size:{X_train.shape[0]} samples\")\n",
    "print(f\"Test set size:{X_test.shape[0]} samples\")\n",
    "\n",
    "# ğŸŒŸ æ›¿æ¢ï¼šå®ä¾‹åŒ–éšæœºæ£®æ— (Random Forest) æ¨¡å‹\n",
    "# n_estimators: æ£®æ—ä¸­æ ‘çš„æ•°é‡ï¼ˆè¶Šå¤šè¶Šå¥½ï¼Œä½†è®¡ç®—æˆæœ¬è¶Šé«˜ï¼‰\n",
    "# criterion: è¡¡é‡åˆ†å‰²è´¨é‡çš„å‡½æ•°\n",
    "# random_state: ç¡®ä¿ç»“æœå¯å¤ç°\n",
    "rf_model = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42)\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"--- Random Forest Model Evaluation ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "if len(y_test.unique()) > 1:\n",
    "    print(classification_report(y_test, pred, zero_division=0))\n",
    "else:\n",
    "    print(\"Classification Report skipped: Only one class in test set.\")\n",
    "\n",
    "# ğŸŒŸ æ›¿æ¢ï¼šä¿å­˜è®­ç»ƒå¥½çš„ Random Forest æ¨¡å‹å’Œ Vectorizer\n",
    "dump(rf_model, 'random_forest_intent_model.joblib')\n",
    "dump(vectorizer, 'tfidf_vectorizerRF.joblib')\n",
    "print(\"Model and Vectorizer saved using joblib.\")\n",
    "\n",
    "# Predefined fixed responses (Retrieval System)\n",
    "print(\"\\n--- Loading Responses from JSON ---\")\n",
    "try:\n",
    "    with open('response.json', 'r', encoding='utf-8') as f:\n",
    "        responses = json.load(f)\n",
    "    print(f\"Successfully loaded {len(responses)} intent-response pairs.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: response.json file not found.\")\n",
    "    responses = {}\n",
    "\n",
    "# ğŸŒŸ æ›¿æ¢ï¼šæ›´æ–°å‡½æ•°å\n",
    "def chatbot_reply_rf(user_input, model, vectorizer, responses):\n",
    "    # 1. Preprocessing\n",
    "    # âš ï¸ å…³é”®ï¼šè¿™é‡Œå¿…é¡»ä½¿ç”¨å®Œæ•´çš„é¢„å¤„ç†å‡½æ•°ï¼Œä¸è®­ç»ƒä¿æŒä¸€è‡´\n",
    "    user_input_cleaned = preprocess_text(user_input)\n",
    "    \n",
    "    # 2. Feature Extraction: Transform the input using the fitted vectorizer\n",
    "    vector = vectorizer.transform([user_input_cleaned])\n",
    "\n",
    "    # 3. Intent Prediction\n",
    "    intent = model.predict(vector)[0]\n",
    "\n",
    "    # 4. Retrieval (Check for unknown intent/fallback)\n",
    "    # If the predicted intent exists in the dictionary, return the specific response\n",
    "    # Otherwise, return a fallback message\n",
    "    return responses.get(intent, f\"Sorry, I predicted the intent '{intent}', but I don't have a specific response for that yet. Please rephrase your question.\")\n",
    "\n",
    "# Test the chatbot function\n",
    "print(\"\\n --- Random Forest Chatbot Test ---\")\n",
    "test_input = \"What time can I check in?\"\n",
    "predicted_response = chatbot_reply_rf(test_input, rf_model, vectorizer, responses)\n",
    "print(f\"User Input: {test_input}\")\n",
    "print(f\"Chatbot Reply: {predicted_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3709fd-4c28-42a0-bb43-6961fc72277d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
