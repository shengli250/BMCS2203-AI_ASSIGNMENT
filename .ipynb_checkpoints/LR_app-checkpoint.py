{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed8729-9a87-466a-8185-50c07d1b2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import joblib\n",
    "import nltk\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# --- Configuration ---\n",
    "CONFIDENCE_THRESHOLD = 0.50  # Threshold for accepting a prediction\n",
    "\n",
    "# --- 1. Load Responses from JSON ---\n",
    "@st.cache_data\n",
    "def load_response_json():\n",
    "    \"\"\"Loads the response configuration from the JSON file.\"\"\"\n",
    "    try:\n",
    "        with open('response.json', 'r', encoding='utf-8') as f:\n",
    "            responses = json.load(f)\n",
    "        if \"unrecognized_intent\" not in responses:\n",
    "            responses[\"unrecognized_intent\"] = \"I'm sorry, I didn't quite catch that. Could you please rephrase?\"\n",
    "        return responses\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"response.json file not found.\")\n",
    "        return {}\n",
    "\n",
    "RESPONSE_DICT = load_response_json()\n",
    "\n",
    "# --- 2. Dynamic Prompt Mapping ---\n",
    "# Create user-friendly prompts from intents found in the JSON\n",
    "PROMPT_MAPPING = {\n",
    "    \"ask_room_price\": \"What are the room rates?\",\n",
    "    \"ask_availability\": \"Do you have rooms available?\",\n",
    "    \"ask_facilities\": \"What facilities do you have?\",\n",
    "    \"ask_location\": \"Where is the hotel located?\",\n",
    "    \"ask_checkin_time\": \"What time is check-in?\",\n",
    "    \"ask_checkout_time\": \"What time is check-out?\",\n",
    "    \"ask_booking\": \"How can I book a room?\",\n",
    "    \"ask_cancellation\": \"Cancellation policy?\",\n",
    "    \"ask_pet_policy\": \"Are pets allowed?\",\n",
    "    \"ask_breakfast_details\": \"Is breakfast included?\",\n",
    "    \"ask_wifi\": \"Is there free Wi-Fi?\",\n",
    "    \"ask_parking\": \"Do you have parking?\",\n",
    "    \"greeting\": \"Hello!\",\n",
    "    \"goodbye\": \"Goodbye!\"\n",
    "}\n",
    "\n",
    "# Generate a list of valid intents for suggestions (excluding simple greetings)\n",
    "SUGGESTED_INTENTS = [\n",
    "    key for key in PROMPT_MAPPING.keys() \n",
    "    if key in RESPONSE_DICT and key not in [\"greeting\", \"goodbye\"]\n",
    "]\n",
    "\n",
    "# --- 3. NLTK Setup ---\n",
    "@st.cache_resource\n",
    "def setup_nltk():\n",
    "    try:\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        nltk.download('punkt_tab', quiet=True)\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        st.error(f\"NLTK Download Error: {e}\")\n",
    "        return False\n",
    "\n",
    "if setup_nltk():\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "else:\n",
    "    stop_words = set()\n",
    "    lemmatizer = None\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocessing function. \n",
    "    MUST match the logic used in 'train_chatbot_lr.py'.\n",
    "    \"\"\"\n",
    "    if not lemmatizer: return text\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# --- 4. Load LR Model & Vectorizer ---\n",
    "@st.cache_resource\n",
    "def load_model_resources():\n",
    "    try:\n",
    "        model = joblib.load('logistic_regression_intent_model.joblib')\n",
    "        vectorizer = joblib.load('tfidf_vectorizer_LR.joblib')\n",
    "        return model, vectorizer\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model files not found! Please run 'train_chatbot_lr.py' first.\")\n",
    "        return None, None\n",
    "\n",
    "lr_model, vectorizer = load_model_resources()\n",
    "\n",
    "# --- 5. Prediction Function ---\n",
    "def predict_intent(text):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if not lr_model or not vectorizer:\n",
    "        return \"error\", \"System Error: Model not loaded.\", \"0%\", 0\n",
    "\n",
    "    # Preprocess\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    \n",
    "    # Vectorize\n",
    "    vector = vectorizer.transform([cleaned_text])\n",
    "    \n",
    "    # Predict Probabilities (Confidence)\n",
    "    # lr_model.predict_proba returns an array of shape (1, n_classes)\n",
    "    probs = lr_model.predict_proba(vector)[0]\n",
    "    \n",
    "    # Get the index of the max probability\n",
    "    max_index = np.argmax(probs)\n",
    "    confidence = probs[max_index]\n",
    "    \n",
    "    # Get the class label (Intent Name)\n",
    "    predicted_intent = lr_model.classes_[max_index]\n",
    "    \n",
    "    # Calculate Response Time\n",
    "    end_time = time.time()\n",
    "    response_time = end_time - start_time\n",
    "\n",
    "    # Threshold Check\n",
    "    if confidence < CONFIDENCE_THRESHOLD:\n",
    "        return \"unrecognized_intent\", RESPONSE_DICT.get(\"unrecognized_intent\"), f\"{confidence*100:.2f}%\", response_time\n",
    "    \n",
    "    # Get Response\n",
    "    response_text = RESPONSE_DICT.get(predicted_intent, \"I understood what you said, but I don't have a response prepared.\")\n",
    "    \n",
    "    return predicted_intent, response_text, f\"{confidence*100:.2f}%\", response_time\n",
    "\n",
    "# --- 6. Streamlit UI ---\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Logistic Regression Chatbot\", layout=\"centered\")\n",
    "    \n",
    "    st.title(\"ðŸ¤– Hotel Assistant (Logistic Regression)\")\n",
    "    st.markdown(\"Fast and efficient intent classification.\")\n",
    "\n",
    "    # Chat History\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "        greeting = RESPONSE_DICT.get(\"greeting\", \"Hello! How can I help?\")\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": greeting})\n",
    "\n",
    "    if \"pending_input\" not in st.session_state:\n",
    "        st.session_state.pending_input = None\n",
    "\n",
    "    # Display History\n",
    "    for msg in st.session_state.messages:\n",
    "        with st.chat_message(msg[\"role\"]):\n",
    "            if msg[\"role\"] == \"assistant\" and \"intent\" in msg:\n",
    "                st.caption(f\"Intent: **{msg['intent']}** | Conf: **{msg['confidence']}** | Time: **{msg['time']:.4f}s**\")\n",
    "            st.markdown(msg[\"content\"])\n",
    "\n",
    "    # Suggested Questions\n",
    "    if SUGGESTED_INTENTS:\n",
    "        # Show 3 random suggestions\n",
    "        suggestions = random.sample(SUGGESTED_INTENTS, min(3, len(SUGGESTED_INTENTS)))\n",
    "        st.markdown(\"---\")\n",
    "        st.markdown(\"**Try asking:**\")\n",
    "        cols = st.columns(len(suggestions))\n",
    "        for i, intent in enumerate(suggestions):\n",
    "            label = PROMPT_MAPPING.get(intent, intent)\n",
    "            with cols[i]:\n",
    "                if st.button(label, key=f\"btn_{intent}\", use_container_width=True):\n",
    "                    st.session_state.pending_input = label\n",
    "                    st.rerun()\n",
    "\n",
    "    # Input Handling\n",
    "    user_input = None\n",
    "    if st.session_state.pending_input:\n",
    "        user_input = st.session_state.pending_input\n",
    "        st.session_state.pending_input = None\n",
    "    else:\n",
    "        user_input = st.chat_input(\"Type your message here...\")\n",
    "\n",
    "    # Process Input\n",
    "    if user_input:\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            intent, response, conf, resp_time = predict_intent(user_input)\n",
    "            \n",
    "            st.session_state.messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response,\n",
    "                \"intent\": intent,\n",
    "                \"confidence\": conf,\n",
    "                \"time\": resp_time\n",
    "            })\n",
    "            st.rerun()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
