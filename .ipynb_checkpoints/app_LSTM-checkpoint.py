import streamlit as st
import pandas as pd
import numpy as np
import joblib
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences

# --- Configuration Parameters ---
MAX_SEQUENCE_LENGTH = 20  # Max number of words used during training
CONFIDENCE_THRESHOLD = 0.75 # New: Threshold to classify as "unrecognized intent"

# --- A. CHATBOT RESPONSE LOOKUP TABLE ---
# This dictionary maps the predicted intent name (string) to a fixed response.
RESPONSE_DICT = {
    "ask_room_price": "Our rooms start from RM180 per night.",
    "ask_availability": "We currently have several rooms available.",
    "ask_facilities": "We offer free Wi-Fi, breakfast, pool, gym and parking.",
    "ask_location": "We are located in Kuala Lumpur City Centre (KLCC).",
    "ask_checkin_time" : "Check-in time is from 2:00 PM.",
    "ask_checkout_time" : "Check-out time is at 12:00 PM.",
    "ask_booking" : "You can book directly through our website or at the front desk.",
    "ask_cancellation" : "Cancellations are free up to 24 hours before arrival.",
    "greeting" : "Hello! How may I assist you today?",
    "goodbye" : "Goodbye! Have a great day!",
    # Default response for unrecognized intents
    "unrecognized_intent": "I apologize, but I currently cannot understand your request. Could you please try rephrasing your question?", 
}

# --- B. Model Loading and Caching ---
# Use Streamlit's caching mechanism to load resources only once
@st.cache_resource
def load_resources():
    """Loads the model, tokenizer, and label encoder from files."""
    try:
        # Load Keras Model
        model = tf.keras.models.load_model('lstm_intent_model.h5')
        
        # Load Tokenizer
        tokenizer = joblib.load('tokenizerLSTM.joblib')
        
        # Load LabelEncoder
        le = joblib.load('label_encoder.joblib')
        
        return model, tokenizer, le
    except FileNotFoundError as e:
        st.error(f"Error loading required model files. Please ensure all files (lstm_intent_model.h5, tokenizer.joblibLSTM, label_encoder.joblib) are in the same directory. Missing file: {e.filename}")
        return None, None, None

model, tokenizer, le = load_resources()

# --- C. Prediction Function ---
def predict_intent(text):
    """
    Predicts the intent of a given text and returns the response.
    Includes logic for 'unrecognized intent' based on confidence.
    """
    if model is None or tokenizer is None or le is None:
        return "Model not loaded. Check the file paths."

    # 1. Preprocess the text
    sequence = tokenizer.texts_to_sequences([text])
    padded_sequence = pad_sequences(sequence, 
                                    maxlen=MAX_SEQUENCE_LENGTH, 
                                    padding='post', 
                                    truncating='post')

    # 2. Make Prediction
    predictions = model.predict(padded_sequence, verbose=0)
    
    # Get the index (ID) of the highest probability
    predicted_id = np.argmax(predictions, axis=1)[0]
    # Get the confidence score (the highest probability)
    confidence_score = np.max(predictions, axis=1)[0]
    
    # 3. Apply Confidence Threshold Logic
    if confidence_score < CONFIDENCE_THRESHOLD:
        # Intent is considered 'unrecognized'
        intent_name = "unrecognized_intent"
        # The corresponding response for 'unrecognized_intent' is retrieved from RESPONSE_DICT
        response = RESPONSE_DICT.get(intent_name)
    else:
        # Convert the predicted ID back to the intent name
        intent_name = le.inverse_transform([predicted_id])[0]
        # Retrieve the specific response for the predicted intent
        response = RESPONSE_DICT.get(intent_name, RESPONSE_DICT['unrecognized_intent'])

    # Format the confidence score to percentage
    confidence_display = f"{confidence_score*100:.2f}%"
    
    return intent_name, response, confidence_display


# --- D. Streamlit App Layout (æ›¿æ¢åŽçš„èŠå¤©è®°å½•æ¨¡å¼) ---
def main():
    st.set_page_config(page_title="Hotel Intent Chatbot", layout="centered")

    st.title("ðŸ›Žï¸ Hotel Intent Recognition Chatbot")
    st.caption(f"LSTM Model | Confidence Threshold: **{CONFIDENCE_THRESHOLD*100:.0f}%**")

    # 1. åˆå§‹åŒ–èŠå¤©åŽ†å² (Session State)
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # å¢žåŠ ä¸€ä¸ªåˆå§‹çš„é—®å€™æ¶ˆæ¯
        st.session_state.messages.append({"role": "assistant", "content": RESPONSE_DICT['greeting']})

    # 2. æ˜¾ç¤ºèŠå¤©åŽ†å²
    # ä½¿ç”¨ st.chat_message æ¥æ¸²æŸ“å¯¹è¯æ°”æ³¡
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # å¦‚æžœæ˜¯åŠ©æ‰‹çš„å›žå¤ï¼Œé¢å¤–æ˜¾ç¤ºç½®ä¿¡åº¦å’Œæ„å›¾
            if message["role"] == "assistant" and "intent" in message:
                st.caption(f"Intent: **{message['intent']}** | Confidence: **{message['confidence']}**")
            st.markdown(message["content"])

    # 3. å¤„ç†ç”¨æˆ·è¾“å…¥
    # ä½¿ç”¨ st.chat_input æ›¿æ¢ st.text_input å’Œ st.button
    user_input = st.chat_input("How may I assist you with your booking?")
    
    if user_input:
        # 3a. å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°åŽ†å²è®°å½•å¹¶æ˜¾ç¤º
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # ç«‹å³åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºç”¨æˆ·è¾“å…¥
        with st.chat_message("user"):
            st.markdown(user_input)

        # 3b. è¿›è¡Œé¢„æµ‹å¹¶ç”Ÿæˆå›žå¤
        with st.spinner('Analyzing query...'):
            intent_name, response, confidence_display = predict_intent(user_input)
            
            # 3c. å°†åŠ©æ‰‹å›žå¤æ·»åŠ åˆ°åŽ†å²è®°å½•
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response,
                "intent": intent_name,
                "confidence": confidence_display
            })

            # 3d. åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºåŠ©æ‰‹å›žå¤
            with st.chat_message("assistant"):
                # é«˜äº®æ˜¾ç¤ºæ„å›¾å’Œç½®ä¿¡åº¦
                st.caption(f"Intent: **{intent_name}** | Confidence: **{confidence_display}**")
                st.markdown(response)

if __name__ == "__main__":
    main()
