import streamlit as st
import joblib
import json
import pandas as pd
import os

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Hotel Chatbot (Naive Bayes)",
    page_icon="ğŸ¨",
    layout="wide"
)

# --- 2. åŠ è½½èµ„æºçš„å‡½æ•° (ä½¿ç”¨ç¼“å­˜æé«˜é€Ÿåº¦) ---

@st.cache_resource
def load_model_and_vectorizer():
    """åŠ è½½æ¨¡å‹å’Œå‘é‡åŒ–å™¨"""
    try:
        model = joblib.load('naive_bayes_intent_model.joblib')
        vectorizer = joblib.load('tfidf_vectorizerNB.joblib')
        return model, vectorizer
    except FileNotFoundError as e:
        st.error(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {e}")
        return None, None

@st.cache_data
def load_responses():
    """åŠ è½½ JSON å›å¤åº“"""
    try:
        with open('response.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        st.error("âŒ æ‰¾ä¸åˆ° response.json æ–‡ä»¶")
        return {}
    except json.JSONDecodeError:
        st.error("âŒ response.json æ–‡ä»¶æ ¼å¼é”™è¯¯")
        return {}

@st.cache_data
def load_dataset():
    """åŠ è½½ CSV æ•°æ®é›†ç”¨äºé¢„è§ˆ"""
    try:
        return pd.read_csv('dataset.csv')
    except Exception:
        return None

# --- 3. åˆå§‹åŒ–åŠ è½½ ---
model, vectorizer = load_model_and_vectorizer()
responses = load_responses()
df = load_dataset()

# --- 4. é¢„æµ‹é€»è¾‘å‡½æ•° ---
def get_prediction(text):
    if not model or not vectorizer:
        return "System Error", "æ¨¡å‹æœªåŠ è½½", 0.0
    
    # é¢„å¤„ç†
    text_clean = text.lower()
    
    # å‘é‡åŒ–
    vector = vectorizer.transform([text_clean])
    
    # é¢„æµ‹æ„å›¾
    intent = model.predict(vector)[0]
    
    # è·å–ç½®ä¿¡åº¦ (Probability) - é€‰åšï¼Œç”¨äºå±•ç¤ºæ¨¡å‹æœ‰å¤šç¡®ä¿¡
    probs = model.predict_proba(vector)[0]
    max_prob = max(probs)
    
    # è·å–å›å¤
    reply = responses.get(intent, "Sorry, I'm not sure how to answer that.")
    
    return intent, reply, max_prob

# --- 5. ä¾§è¾¹æ  (Sidebar) ---
with st.sidebar:
    st.header("ğŸ¤– æ¨¡å‹æ§åˆ¶å°")
    st.write("è¿™æ˜¯ä¸€ä¸ªåŸºäº Naive Bayes çš„æ„å›¾è¯†åˆ«èŠå¤©æœºå™¨äººã€‚")
    
    st.divider()
    
    # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
    if model and vectorizer:
        st.success("âœ… æ¨¡å‹å·²åŠ è½½")
    else:
        st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")

    if responses:
        st.success(f"âœ… å·²åŠ è½½ {len(responses)} æ¡å›å¤è§„åˆ™")

    # æ•°æ®é›†é¢„è§ˆ
    st.divider()
    st.subheader("ğŸ“Š è®­ç»ƒæ•°æ®é¢„è§ˆ")
    if df is not None:
        st.dataframe(df.head(10), use_container_width=True)
        st.caption(f"å…± {len(df)} æ¡æ•°æ®")
    else:
        st.warning("æœªæ‰¾åˆ° dataset.csv")

# --- 6. ä¸»èŠå¤©ç•Œé¢ ---
st.title("ğŸ¨ Hotel Assistant Bot")
st.caption("Ask me about room prices, check-in times, or facilities!")

# åˆå§‹åŒ–èŠå¤©å†å² (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Hello! How can I help you with your hotel booking today?"}]

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 7. å¤„ç†ç”¨æˆ·è¾“å…¥ ---
if prompt := st.chat_input("Type your message here..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. è·å–æ¨¡å‹é¢„æµ‹
    intent, reply, confidence = get_prediction(prompt)

    # 3. æ˜¾ç¤ºæœºå™¨äººå›å¤
    st.session_state.messages.append({"role": "assistant", "content": reply})
    with st.chat_message("assistant"):
        st.markdown(reply)
        
        # å¯é€‰ï¼šåœ¨å›å¤ä¸‹æ–¹æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ (æ„å›¾å’Œç½®ä¿¡åº¦)
        with st.expander("ğŸ” Debug Info (Model Prediction)"):
            st.write(f"**Predicted Intent:** `{intent}`")
            st.write(f"**Confidence:** `{confidence:.2%}`")