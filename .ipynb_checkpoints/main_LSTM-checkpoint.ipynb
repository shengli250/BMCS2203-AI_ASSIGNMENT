{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e26adbd-d92c-43f3-9dd4-adeadb8d257b",
   "metadata": {},
   "source": [
    "# Hotel Booking Chatbot\n",
    "## Core NLP: Deep Learning Intent Classifier - LSTM\n",
    "\n",
    "This component implements the Intent Classification module, designed to categorize user queries into one of 10 predefined hotel booking intents.\n",
    "\n",
    "- Model: Sequential LSTM Network (Long Short-Term Memory).\n",
    "- Frameworks: Keras} and TensorFlow.\n",
    "- Output: Includes detailed performance metrics (F1 Score, Precision, Recall) and necessary files exported for platform deployment (e.g., Streamlit).\n",
    "\n",
    "This approach provides high accuracy and performance for complex text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf7474-2b9a-4076-a256-045621cfdd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install necessary libraries\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815e143-c22d-439b-be1e-399dcefe1762",
   "metadata": {},
   "source": [
    "## STEP 1: Setup and Configuration\n",
    "\n",
    "This cell imports necessary libraries and defines configuraton parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf968c7-4878-4a0f-8c01-b4e23f703adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# TensorFlow/Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# --- Configuration Parameters ---\n",
    "MAX_SEQUENCE_LENGTH = 20  # Max number of words to consider per sentence\n",
    "EMBEDDING_DIM = 100       # Dimension for the learned word embeddings\n",
    "EPOCHS = 40               # Number of training epochs\n",
    "BATCH_SIZE = 32           # Number of samples per gradient update\n",
    "TEST_SIZE = 0.2           # 20% of data for testing\n",
    "RANDOM_STATE = 42         # For reproducible results\n",
    "\n",
    "# --- A. CHATBOT RESPONSE LOOKUP TABLE ---\n",
    "# This dictionary maps the predicted intent name (string) to a fixed response.\n",
    "RESPONSE_DICT = {\n",
    "    \"ask_room_price\": \"Our standard room price is 150 MYR per night, and a deluxe room is 250 MYR. Which room type would you like to inquire about?\",\n",
    "    \"ask_availability\": \"Could you please provide the check-in and check-out dates? I can check real-time room availability for you.\",\n",
    "    \"ask_facilities\": \"We offer free Wi-Fi, complimentary parking, an indoor swimming pool, and a 24-hour gym.\",\n",
    "    \"ask_location\": \"Our hotel is situated in the city center, close to the central station and major shopping areas. You can find the full address on our website.\",\n",
    "    \"ask_checkin_time\": \"Our standard check-in time is 3:00 PM. Please contact the front desk if you require early check-in.\",\n",
    "    \"ask_checkout_time\": \"Please ensure you check out before 12:00 PM (noon). Late check-outs may incur an additional charge.\",\n",
    "    \"ask_booking\": \"You can make a reservation through our official website, by calling our booking hotline, or via major online travel platforms.\",\n",
    "    \"ask_cancellation\": \"Our cancellation policy depends on your booking type. Generally, cancellation is free if done 24 hours in advance.\",\n",
    "    \"greeting\": \"Hello! I am happy to assist you. How may I help you with your booking or answer your questions?\",\n",
    "    \"goodbye\": \"Thank you for reaching out! Have a wonderful day. Feel free to contact me if you have any other questions.\",\n",
    "    \"default\": \"I apologize, but I currently cannot understand your request. Could you please try rephrasing your question?\" # Default response for unrecognized intents\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d20401-08e1-42e2-b9e9-3f4e0bcc9f79",
   "metadata": {},
   "source": [
    "## STEP 2: Data Loading and Preprocessing\n",
    "\n",
    "Load the data, encode that intent labels into numerical IDs, and split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaaa9edf-ac7d-41a5-be39-86142e43f0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique intent classes: 10\n",
      "Training samples: 80, Testing samples: 20\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['intent'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Split data: 80% train, 20% test (stratified for balanced classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Number of unique intent classes: {num_classes}\")\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b088e-1fd7-4b12-8fd1-ecf20e5e337c",
   "metadata": {},
   "source": [
    "## STEP 3: Tokenization and Data Preparation for DL\n",
    "\n",
    "Convert text data into numerical sequences (tokens) and apply padding, and convert labels to One-Hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98075f17-eb95-4b90-8633-4b5ed3a5368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 124\n",
      "Padded Training Data Shape: (80, 20)\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize and fit Tokenizer\n",
    "tokenizer = Tokenizer(num_words=None, oov_token=\"<unk>\") \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 2. Convert text to sequences of integers\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "word_index = tokenizer.word_index\n",
    "VOCAB_SIZE = len(word_index) + 1 # Vocabulary size\n",
    "\n",
    "# 3. Padding sequences (standardize input size)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# 4. One-Hot Encode the labels\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(f\"Vocabulary Size: {VOCAB_SIZE}\")\n",
    "print(f\"Padded Training Data Shape: {X_train_padded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317110d-11ff-45d1-b438-5d5f1dc0d120",
   "metadata": {},
   "source": [
    "## STEP 4: Build, Compile and Train the LSTM Model\n",
    "\n",
    "Define the Embedding + LSTM architecture and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f876cb0-5d57-41b9-b9a1-38675a8531c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Structure and Training Started ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (\u001b[38;5;33mEmbedding\u001b[0m)          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_layer (\u001b[38;5;33mLSTM\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - accuracy: 0.0972 - loss: 2.3047 - val_accuracy: 0.0000e+00 - val_loss: 2.3179\n",
      "Epoch 2/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1250 - loss: 2.2961 - val_accuracy: 0.0000e+00 - val_loss: 2.3283\n",
      "Epoch 3/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1667 - loss: 2.3008 - val_accuracy: 0.0000e+00 - val_loss: 2.3306\n",
      "Epoch 4/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0833 - loss: 2.3123 - val_accuracy: 0.1250 - val_loss: 2.3281\n",
      "Epoch 5/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0833 - loss: 2.3032 - val_accuracy: 0.1250 - val_loss: 2.3274\n",
      "Epoch 6/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0972 - loss: 2.2913 - val_accuracy: 0.1250 - val_loss: 2.3291\n",
      "Epoch 7/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1111 - loss: 2.3000 - val_accuracy: 0.1250 - val_loss: 2.3317\n",
      "Epoch 8/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0972 - loss: 2.2972 - val_accuracy: 0.1250 - val_loss: 2.3384\n",
      "Epoch 9/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1250 - loss: 2.3024 - val_accuracy: 0.0000e+00 - val_loss: 2.3473\n",
      "Epoch 10/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1250 - loss: 2.3034 - val_accuracy: 0.0000e+00 - val_loss: 2.3512\n",
      "Epoch 11/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0833 - loss: 2.2999 - val_accuracy: 0.0000e+00 - val_loss: 2.3589\n",
      "Epoch 12/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.1111 - loss: 2.2973 - val_accuracy: 0.0000e+00 - val_loss: 2.3649\n",
      "Epoch 13/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.1250 - loss: 2.2812 - val_accuracy: 0.0000e+00 - val_loss: 2.3856\n",
      "Epoch 14/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1389 - loss: 2.2925 - val_accuracy: 0.0000e+00 - val_loss: 2.4135\n",
      "Epoch 15/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1111 - loss: 2.2959 - val_accuracy: 0.0000e+00 - val_loss: 2.4112\n",
      "Epoch 16/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1667 - loss: 2.2708 - val_accuracy: 0.0000e+00 - val_loss: 2.3809\n",
      "Epoch 17/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2083 - loss: 2.2503 - val_accuracy: 0.0000e+00 - val_loss: 2.3632\n",
      "Epoch 18/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1806 - loss: 2.2220 - val_accuracy: 0.1250 - val_loss: 2.3106\n",
      "Epoch 19/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2917 - loss: 2.0944 - val_accuracy: 0.1250 - val_loss: 2.3003\n",
      "Epoch 20/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2778 - loss: 1.9051 - val_accuracy: 0.1250 - val_loss: 2.0416\n",
      "Epoch 21/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3333 - loss: 1.8593 - val_accuracy: 0.1250 - val_loss: 1.9673\n",
      "Epoch 22/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1944 - loss: 1.8427 - val_accuracy: 0.1250 - val_loss: 2.1713\n",
      "Epoch 23/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2639 - loss: 1.6986 - val_accuracy: 0.2500 - val_loss: 1.8928\n",
      "Epoch 24/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4444 - loss: 1.5874 - val_accuracy: 0.2500 - val_loss: 1.8592\n",
      "Epoch 25/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3056 - loss: 1.5563 - val_accuracy: 0.2500 - val_loss: 1.9548\n",
      "Epoch 26/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4028 - loss: 1.3795 - val_accuracy: 0.3750 - val_loss: 1.8280\n",
      "Epoch 27/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4306 - loss: 1.3721 - val_accuracy: 0.5000 - val_loss: 1.5668\n",
      "Epoch 28/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5278 - loss: 1.1883 - val_accuracy: 0.6250 - val_loss: 1.6269\n",
      "Epoch 29/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5694 - loss: 1.1777 - val_accuracy: 0.5000 - val_loss: 1.5347\n",
      "Epoch 30/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6389 - loss: 0.9732 - val_accuracy: 0.3750 - val_loss: 1.6303\n",
      "Epoch 31/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6528 - loss: 0.8796 - val_accuracy: 0.6250 - val_loss: 1.4957\n",
      "Epoch 32/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.8619 - val_accuracy: 0.5000 - val_loss: 1.7368\n",
      "Epoch 33/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 1.2953\n",
      "Epoch 34/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7778 - loss: 0.6810 - val_accuracy: 0.5000 - val_loss: 1.3925\n",
      "Epoch 35/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8472 - loss: 0.5527 - val_accuracy: 0.5000 - val_loss: 1.4073\n",
      "Epoch 36/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8472 - loss: 0.5010 - val_accuracy: 0.3750 - val_loss: 1.5968\n",
      "Epoch 37/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8750 - loss: 0.4130 - val_accuracy: 0.5000 - val_loss: 1.8047\n",
      "Epoch 38/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8333 - loss: 0.3733 - val_accuracy: 0.5000 - val_loss: 1.8142\n",
      "Epoch 39/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8889 - loss: 0.3378 - val_accuracy: 0.6250 - val_loss: 1.6535\n",
      "Epoch 40/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9167 - loss: 0.2505 - val_accuracy: 0.6250 - val_loss: 1.6328\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM Model\n",
    "model = Sequential([\n",
    "    # Embedding Layer: Maps word indices to dense vectors\n",
    "    Embedding(input_dim=VOCAB_SIZE, \n",
    "              output_dim=EMBEDDING_DIM, \n",
    "              input_length=MAX_SEQUENCE_LENGTH,\n",
    "              name='embedding_layer'),\n",
    "    \n",
    "    # LSTM Layer: Captures sequential and long-term dependencies\n",
    "    LSTM(units=128, \n",
    "         return_sequences=False, # Output only the final state for classification\n",
    "         name='lstm_layer'),\n",
    "    \n",
    "    # Dropout: Regularization\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Dense Output Layer: Softmax for multi-class prediction\n",
    "    Dense(units=num_classes, activation='softmax', name='output_layer')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"--- Model Structure and Training Started ---\")\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_padded, y_train_one_hot,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d8877-ed79-4612-bfaf-18ccb2bab929",
   "metadata": {},
   "source": [
    "## STEP 5: Evaluate Intent Recognition Performance (Accuracy, F1, Precision, Recall)\n",
    "\n",
    "Calculate and display the detailed metrics required for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b719c83-9742-4c00-ba75-199dfa509dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "\n",
      "--- Intent Recognition Performance Evaluation ---\n",
      "Test Accuracy (Accuracy of Intent Recognition): 0.7500\n",
      "Test Loss: 1.3146\n",
      "\n",
      "--- Detailed Classification Report (F1, Precision, Recall) ---\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " ask_availability       0.00      0.00      0.00         2\n",
      "      ask_booking       1.00      1.00      1.00         2\n",
      " ask_cancellation       0.67      1.00      0.80         2\n",
      " ask_checkin_time       1.00      1.00      1.00         2\n",
      "ask_checkout_time       1.00      1.00      1.00         2\n",
      "   ask_facilities       0.00      0.00      0.00         2\n",
      "     ask_location       1.00      1.00      1.00         2\n",
      "   ask_room_price       1.00      1.00      1.00         2\n",
      "          goodbye       0.67      1.00      0.80         2\n",
      "         greeting       1.00      0.50      0.67         2\n",
      "\n",
      "         accuracy                           0.75        20\n",
      "        macro avg       0.73      0.75      0.73        20\n",
      "     weighted avg       0.73      0.75      0.73        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test_one_hot, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = model.predict(X_test_padded)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1) # Convert probabilities to class IDs\n",
    "y_true = y_test.values                   # Get true class IDs\n",
    "\n",
    "# Get intent names for the report\n",
    "intent_names = le.classes_\n",
    "\n",
    "\n",
    "print(f\"\\n--- Intent Recognition Performance Evaluation ---\")\n",
    "print(f\"Test Accuracy (Accuracy of Intent Recognition): {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "\n",
    "# Print F1 Score, Precision, and Recall report\n",
    "print(\"\\n--- Detailed Classification Report (F1, Precision, Recall) ---\")\n",
    "print(classification_report(y_true, y_pred, target_names=intent_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b090a-6e1d-4366-ac3d-2514e7b966bc",
   "metadata": {},
   "source": [
    "## STEP 6: Model Export for Streamlit Deployment\n",
    "\n",
    "Export the Keras model and preprocessing components (Tokenizer, LabelEncoder) to the current working directory using .h5 and .joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a60276e-2c39-497f-841d-0f171d61d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EXPORT SUCCESS] Keras Model saved to: lstm_intent_model.h5\n",
      "[EXPORT SUCCESS] Tokenizer saved to: tokenizer.joblibLSTM\n",
      "[EXPORT SUCCESS] LabelEncoder saved to: label_encoder.joblib\n",
      "\n",
      "--- Deployment Files Ready in Current Directory ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Export Keras Model (.h5 format)\n",
    "model_path = 'lstm_intent_model.h5'\n",
    "model.save(model_path)\n",
    "print(f\"\\n[EXPORT SUCCESS] Keras Model saved to: {model_path}\")\n",
    "\n",
    "# 2. Export Tokenizer (using joblib)\n",
    "tokenizer_path = 'tokenizer.joblibLSTM'\n",
    "joblib.dump(tokenizer, tokenizer_path)\n",
    "print(f\"[EXPORT SUCCESS] Tokenizer saved to: {tokenizer_path}\")\n",
    "\n",
    "# 3. Export LabelEncoder (using joblib)\n",
    "label_encoder_path = 'label_encoder.joblib'\n",
    "joblib.dump(le, label_encoder_path)\n",
    "print(f\"[EXPORT SUCCESS] LabelEncoder saved to: {label_encoder_path}\")\n",
    "\n",
    "print(\"\\n--- Deployment Files Ready in Current Directory ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c3e98-0a3b-478e-b731-a8ecd41cdb2a",
   "metadata": {},
   "source": [
    "## STEP 7: Prediction Example\n",
    "\n",
    "Use the exported components to demonstrate how the model predicts the intent for new, unseen user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcce0bf3-1dca-4831-8dce-79034e7d005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 7. Prediction Example - Includes Chatbot Response ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "\n",
      "--- USER QUERY: I need to cancel my room now\n",
      "--- PREDICTED INTENT: ask_booking\n",
      "--- CHATBOT RESPONSE: You can make a reservation through our official website, by calling our booking hotline, or via major online travel platforms.\n",
      "\n",
      "--- USER QUERY: What is the cheapest room?\n",
      "--- PREDICTED INTENT: ask_room_price\n",
      "--- CHATBOT RESPONSE: Our standard room price is 150 MYR per night, and a deluxe room is 250 MYR. Which room type would you like to inquire about?\n",
      "\n",
      "--- USER QUERY: Hello\n",
      "--- PREDICTED INTENT: greeting\n",
      "--- CHATBOT RESPONSE: Hello! I am happy to assist you. How may I help you with your booking or answer your questions?\n",
      "\n",
      "--- USER QUERY: Where is the hotel located?\n",
      "--- PREDICTED INTENT: ask_location\n",
      "--- CHATBOT RESPONSE: Our hotel is situated in the city center, close to the central station and major shopping areas. You can find the full address on our website.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 7. Prediction Example - Includes Chatbot Response ---\")\n",
    "\n",
    "# Example user queries\n",
    "new_text = [\n",
    "    \"I need to cancel my room now\", # Expected: ask_cancellation\n",
    "    \"What is the cheapest room?\",    # Expected: ask_room_price\n",
    "    \"Hello\",                         # Expected: greeting\n",
    "    \"Where is the hotel located?\"    # Expected: ask_location\n",
    "]\n",
    "\n",
    "# Step 1: Preprocess the new text using the trained Tokenizer and Padding\n",
    "new_sequences = tokenizer.texts_to_sequences(new_text)\n",
    "new_padded = pad_sequences(new_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Step 2: Make predictions\n",
    "predictions = model.predict(new_padded)\n",
    "\n",
    "# Step 3: Find the intent ID with the highest probability\n",
    "predicted_intent_id = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Step 4: Convert the predicted ID back to the intent name using the LabelEncoder\n",
    "predicted_intent_name = le.inverse_transform(predicted_intent_id)\n",
    "\n",
    "for query, intent in zip(new_text, predicted_intent_name):\n",
    "    # Retrieve the response based on the predicted intent\n",
    "    # Use .get() with 'default' key as a fallback for robustness\n",
    "    response = RESPONSE_DICT.get(intent, RESPONSE_DICT['default'])\n",
    "    \n",
    "    print(f\"\\n--- USER QUERY: {query}\")\n",
    "    print(f\"--- PREDICTED INTENT: {intent}\")\n",
    "    print(f\"--- CHATBOT RESPONSE: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e6732-42e6-4e8b-9fd3-73db29dfbea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
