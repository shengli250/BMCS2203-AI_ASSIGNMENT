import streamlit as st
import numpy as np
import joblib
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import re
from sklearn.svm import SVC # ÂØºÂÖ•Ê®°ÂûãÁ±ªÂûã

# --- Configuration Parameters ---
# ÂØπ‰∫é SVM ÁöÑ probability=True ËæìÂá∫ÁöÑÊ¶ÇÁéáÔºå0.70 Âà∞ 0.85 ÊòØÂêàÁêÜÁöÑËµ∑ÂßãÁÇπ
CONFIDENCE_THRESHOLD = 0.7 

# --- A. CHATBOT RESPONSE LOOKUP TABLE ---
RESPONSE_DICT = {
    "ask_room_price": "Our rooms start from RM180 per night.",
    "ask_availability": "We currently have several rooms available.",
    "ask_facilities": "We offer free Wi-Fi, breakfast, pool, gym and parking.",
    "ask_location": "We are located in Kuala Lumpur City Centre (KLCC).",
    "ask_checkin_time" : "Check-in time is from 2:00 PM.",
    "ask_checkout_time" : "Check-out time is at 12:00 PM.",
    "ask_booking" : "You can book directly through our website or at the front desk.",
    "ask_cancellation" : "Cancellations are free up to 24 hours before arrival.",
    "greeting" : "Hello! How may I assist you today?",
    "goodbye" : "Goodbye! Have a great day!",
    # Default response for unrecognized intents
    "unrecognized_intent": "I apologize, but I currently cannot understand your request. Could you please try rephrasing your question?", 
}

# --- B. NLTK Download and Preprocessing Setup (Cached) ---
@st.cache_resource(show_spinner="Downloading NLTK resources...")
def download_nltk_resources():
    """Downloads necessary NLTK resources and initializes objects."""
    try:
        nltk.download('punkt', quiet=True)
        nltk.download('punkt_tab', quiet=True)
        nltk.download('wordnet', quiet=True)
        nltk.download('stopwords', quiet=True)
        stop_words = set(stopwords.words('english'))
        lemmatizer = WordNetLemmatizer()
        return True, stop_words, lemmatizer
    except Exception as e:
        st.error(f"Failed to download NLTK resources: {e}")
        return False, set(), None

is_nltk_ready, stop_words, lemmatizer = download_nltk_resources()

def preprocess_text(text):
    """Applies the same preprocessing steps as the training script."""
    if not lemmatizer:
        return "" 
        
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    tokens = word_tokenize(text)
    tokens = [word for word in tokens if word not in stop_words]
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return ' '.join(tokens)

# --- C. Model Loading and Caching ---
@st.cache_resource
def load_resources():
    """Loads the model and vectorizer from files."""
    try:
        # Load SVM Model
        svm_model = joblib.load('svm_intent_model.joblib')
        
        # Load TFIDF Vectorizer
        vectorizer = joblib.load('tfidf_vectorizer_SVM.joblib') 
        
        return svm_model, vectorizer
    except FileNotFoundError as e:
        st.error(f"Error loading required model files. Please ensure all files (svm_intent_model.joblib, tfidf_vectorizer_SVM.joblib) are in the same directory. Missing file: {e.filename}")
        return None, None

svm_model, vectorizer = load_resources()

# --- D. Prediction Function ---
def predict_intent(text):
    """
    Predicts the intent using the SVM model and applies a confidence threshold.
    """
    if svm_model is None or vectorizer is None or not is_nltk_ready:
        return "setup_error", RESPONSE_DICT.get("unrecognized_intent"), "N/A"

    # 1. Preprocessing and Feature Extraction
    user_input_cleaned = preprocess_text(text)
    vector = vectorizer.transform([user_input_cleaned])

    # 2. Get Probability Predictions
    # ‚ö†Ô∏è Requires SVC(probability=True) during training
    try:
        predictions_proba = svm_model.predict_proba(vector)[0]
    except AttributeError:
        # Fallback if probability=False was used during training
        st.error("Error: The SVM model was not trained with `probability=True`. Cannot calculate confidence.")
        return "model_error", RESPONSE_DICT.get("unrecognized_intent"), "N/A"
    
    # Get the index (ID) of the highest probability
    predicted_index = np.argmax(predictions_proba)
    # Get the confidence score (the highest probability)
    confidence_score = np.max(predictions_proba)
    
    # Get the predicted intent name 
    predicted_intent_name = svm_model.classes_[predicted_index]

    # 3. Apply Confidence Threshold Logic
    if confidence_score < CONFIDENCE_THRESHOLD:
        intent_name = "unrecognized_intent"
        response = RESPONSE_DICT.get(intent_name)
    else:
        intent_name = predicted_intent_name
        # Retrieve the specific response for the predicted intent
        response = RESPONSE_DICT.get(intent_name, RESPONSE_DICT['unrecognized_intent'])

    confidence_display = f"{confidence_score*100:.2f}%"
    
    return intent_name, response, confidence_display


# --- E. Streamlit App Layout (Â∏¶ËÅäÂ§©ËÆ∞ÂΩïÊ®°Âºè) ---
def main():
    st.set_page_config(page_title="SVM Intent Chatbot (Chat History)", layout="centered")

    st.title("üõ°Ô∏è Hotel Chatbot (Support Vector Machine)")
    st.caption(f"Confidence Threshold: **{CONFIDENCE_THRESHOLD*100:.0f}%**")

    # 1. ÂàùÂßãÂåñËÅäÂ§©ÂéÜÂè≤ (Session State)
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # Â¢ûÂä†‰∏Ä‰∏™ÂàùÂßãÁöÑÈóÆÂÄôÊ∂àÊÅØ
        st.session_state.messages.append({"role": "assistant", "content": RESPONSE_DICT['greeting']})

    # 2. ÊòæÁ§∫ËÅäÂ§©ÂéÜÂè≤
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant" and "intent" in message:
                st.caption(f"Intent: **{message['intent']}** | Confidence: **{message['confidence']}**")
            st.markdown(message["content"])

    # 3. Â§ÑÁêÜÁî®Êà∑ËæìÂÖ•
    user_input = st.chat_input("How may I assist you with your reservation?")
    
    if user_input:
        # 3a. Â∞ÜÁî®Êà∑ËæìÂÖ•Ê∑ªÂä†Âà∞ÂéÜÂè≤ËÆ∞ÂΩïÂπ∂ÊòæÁ§∫
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        with st.chat_message("user"):
            st.markdown(user_input)

        # 3b. ËøõË°åÈ¢ÑÊµãÂπ∂ÁîüÊàêÂõûÂ§ç
        with st.spinner('Analyzing query...'):
            intent_name, response, confidence_display = predict_intent(user_input)
            
            # 3c. Â∞ÜÂä©ÊâãÂõûÂ§çÊ∑ªÂä†Âà∞ÂéÜÂè≤ËÆ∞ÂΩï
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response,
                "intent": intent_name,
                "confidence": confidence_display
            })

            # 3d. Âú®ÁïåÈù¢‰∏äÊòæÁ§∫Âä©ÊâãÂõûÂ§ç
            with st.chat_message("assistant"):
                st.caption(f"Intent: **{intent_name}** | Confidence: **{confidence_display}**")
                st.markdown(response)

if __name__ == "__main__":
    main()
